\subsection{Elements}
A supervised task is made of many elements, for instance, we need a label definition, 
actual data points to observe and a measure of the performance and the error to guide the 
algorithm.

\subsubsection{Labels}
Along with the definition of a learning problem, there is a label set $Y$ that collects
possible labels of data.\\
For instance, when considering classification of documents, a label set could be defined 
as follows: 
$$Y = \{\mathit{sport}, \mathit{politics}, \mathit{business}, \dots\}$$
Or in the case of stock predictions:
$$Y \subseteq \mathbb{R}$$

\paragraph{Labels definition}
The definition of labels changes the flavour of the task, in fact:
\begin{itemize}
    \item if $Y$ contains a finite number of symbols the task 
    is called \emph{classification}/\emph{categorization}
    \item if $Y$ is formed by real numbers, the task is called \emph{regression}
\end{itemize}

\paragraph{Error measures}
The computation of prediction error differs between classification and regression:
in the first we can consider an error if the prediction differs from the label, 
in the latter we can compute the difference between the prediction and the label.

\subsubsection{Loss functions}
When learning a map from data to labels, we need a way to tell the machine how good
the mapping is, so a loss function is defined on the pair of true label and assigned label.

\paragraph{Classification loss examples}
In case of classification, we can define:
\[
    l(y, \hat{y}) = \begin{cases}
        0\; \mathit{if}\; y = \hat{y}\\
        1\; \mathit{if}\; y \neq \hat{y}\\
\end{cases}\]

It is possible to be a little more precise in the definition of a loss function, for instance:
$$Y = \{\mathit{spam}, \mathit{notspam}\}$$
\[
    l(y, \hat{y}) = \begin{cases}
        2\; \mathit{if}\; y = \mathit{notspam} \wedge \hat{y} = \mathit{spam}\\
        1\; \mathit{if}\; y = \mathit{spam} \wedge \hat{y} = \mathit{notspam}\\
        0\; \mathit{otherwise}
\end{cases}\]
The idea is to penalize false positive mistakes, giving them a $2$ contribution, 
and to count false negative mistakes. 

\paragraph{Regression loss examples}
An example of a loss function in the case of regression are the \emph{absolute loss}:
$$l(y, \hat{y}) = |y - \hat{y}|$$
ot the \emph{square loss} that has some better properties:
$$l(y, \hat{y}) = (y - \hat{y})^2$$
Another example, in the case of whether forecast prediction:
$$Y = \{\mathit{rain}, \mathit{sun}\}, Z = [0,1]$$
We want to define a regression task that outputs the probability of a whether condition.
By using the absolute error loss function, we assume a linearity in the error, 
whereas we can assume that predicting sun while it rains can be a shame.\\
This means it is preferred to use something like a square loss, to keep track of such a 
wanted behavior, indeed the error would raise quicker and exponentially.

Another example would be the \emph{logarithmic loss}:
\[
    l(y, \hat{y}) = \begin{cases}
        \ln \frac{1}{\hat{y}}\; \mathit{if}\; y = 1\\
        \ln \frac{1}{1-\hat{y}}\; \mathit{if}\; y = 0
\end{cases}\]
$$\lim_{\hat{y} \rightarrow 0^+} l(1, \hat{y}) = \lim_{\hat{y} \rightarrow 1^-} l(0, \hat{y}) = \infty$$

This means the algorithm will pay an infinite punishment when making wrong predictions.

\subsubsection{Data points}
The data points encode individual data, such as individual documents, medical records, 
measurements, and so on. They are digitally stored somewhere.\\
We define with $X$ the data domain.

\paragraph{Encoding}
To not loose generality, we would data to \emph{look the same} to a learning algorithm, 
so it is preferred to have some sort of encoding. Such encoding usually maps $X$ to a 
vector of numbers.\\
For instance images can be represented as vectors of pixels, and texts can use 
something like a frequency vector given a dictionary.

The power of encoding is that after a mapping data points become points in a space, 
so we can use geometry to face the machine learning task.\\
Let's consider classification, with a good encoding, usually points related to each 
other, so points of the same class, are close together.

Data points can be
\[
    X = \begin{cases}
        \mathbb{R}^d\;\mathit{numerical\;attributes}\\
        X_1, \dots, X_d\; \mathit{categorical\;attributes}
    \end{cases}\]

\paragraph{Problems with numerical attributes}
A geometric interpretation for such problems is straight forward, as we can use data
points as coordinates.

\paragraph{Problems with categorical attributes}
If a certain attribute does not have a geometrical interpretation, for instance there is 
no order on the domain of the attribute, it is helpful to use \emph{One-hot encoding}.
For instance, to use the sex of a person as a dimension, we must define an order and a mapping
to numbers.

\begin{remark}
    When using encoding, the created order over categorical attributes can be 
    a problem.
    There is no golden rule to approach an encoding task, it is a trial and error process, 
    a bad encoding can destroy data meaning.
\end{remark}

\subsubsection{Learning predictors}
A predictor is a function that maps data points to labels, or predictions 
if they differ from labels
$$f : X \longrightarrow Y, f: X \longrightarrow Z, Z \neq Y$$
So given a data point $x$, the prediction is made as follows
$$\hat{y} = f(x)$$
The prediction function must be learned, and the general goal is 
to have a small loss $l(y, \hat{y})$ over \emph{most} of the data points.

\paragraph{Data points annotation}
As we are in a supervised task, we can construct a predictor using labeled data.
A single data point is a tuple
$$(x, y) \longrightarrow (\mathit{data\;point}, \mathit{label})$$
When talking about labels, they can be:
\begin{enumerate}
    \item \emph{Subjective}: human annotation
    \item \emph{Objective}: objective measurements
\end{enumerate}
In the first case, labels may not be consistent and contain noise.

\paragraph{Training set}
A training set is a set of training examples.
The main idea is to pass the training set to a learning algorithm, 
that considers a certain loss function to finally produce 
a predictor.
$$\mathit{training\;set} \longrightarrow \mathit{learning\;algorithm}
\longrightarrow \mathit{predictor}$$

\paragraph{Test set}
A test set is a set of unseen examples, used to evaluate the predictor 
performance. Typically a whole dataset is splitted into the training and test sets.
$$\mathit{dataset} \longrightarrow (\mathit{training\;set}, \mathit{test\;set})$$

\paragraph{Test error}
Let's now consider a predictor $f$ learned by a certain learning algorithm $A$ 
using a loss function $l$.
We can compute the test error as follows
$$\mathit{test\;set} = (x^\prime_1, y^\prime_1), \dots,(x^\prime_n, y^\prime_n)$$
$$\mathit{error} = \frac{1}{n}\sum_{t=1}^n l(y^\prime_t, f(x^\prime_t))$$
Test error is a proxy for the behavior of the predictor \emph{in the field}.

\begin{remark}
    Our goal is to develop a theory to guide us into the design of learning algorithms 
    that generates predictors with small test error with respect to some loss function.\\
    Having more data should be convenient to reduce the test error.
\end{remark}

\paragraph{Training error}
Given a training set
$$S = (x_1, y_1), \dots,(x_m, y_m)$$
The algorithm knows a loss function $l$, the training error can be computed as follows
$$\hat{l}_s(f) = \frac{1}{m}\sum_{t=1}^m l(y_t, f(x_t))$$
The idea is that the learning algorithm can infer the test error from the training error.

\section{Empirical risk minimizer}
The main idea of the Empirical risk minimizer is to find the best predictor given 
a training set and a loss function.

Formally, we define $F$ as a set of predictors, and $l$ a loss function.\\
The ERM works like this:
$$\mathit{training\;set} \longrightarrow \mathit{ERM} \longrightarrow 
\hat{f} \in \min_{f \in F} \hat{l}_S(f)$$

Things can go wrong, for instance if the minimum error
$$\min_{f \in F} \frac{1}{n}\sum_{t = 1}^n l(y_t^\prime, f(x_t^\prime))$$
is large, we can't find a good predictor. The solution could be increasing the $F$ domain, 
but that's not always the case.

\paragraph{Example}
Let's consider the example below, where we want to predict these labels.
$$X = \{x_1, \dots, x_5\}, Y = \{-1,1\}, l = \mathit{zero\;one\;loss}$$
$F$ contains all the binary classifiers like
$f : \{x_1, \dots, x_5\} \longrightarrow \{-1,1\}$
so we have that $|F| = 2^5 = 32$. 

Let's now consider 4 predictors for the 5 data points
\begin{center}
    \begin{tabular}{l c c c c c}
     & $x_1$ & $x_2$ & $x_3$ & $x_4$ & $x_5$ \\
     Labels & -1 & 1 & 1 & 1 & 1\\
     \hline
    $f_1$ & -1 & 1 & 1 & 1 & 1 \\
    $f_2$ & -1 & 1 & 1 & -1 & 1 \\
    $f_3$ & -1 & 1 & 1 & 1 & -1 \\
    $f_4$ & -1 & 1 & 1 & -1 & -1 \\
    \end{tabular}
\end{center}
If the training set is made of the first 3 data points, namely 
$$S = \{(x_i, y_i)\}, i \in \{1,2,3\}$$
All the 4 predictors would have the same, null, training error.
In such a case we can't decide what predictor to use, as training error do not give 
us any relevant information.

As a rule of thumb, given $m$ the size of the training set $S$, if $F$ is bound, 
the following should hold
$$m \geq \log_2 F$$

\paragraph{Underfitting and overfitting} 
The first means having too few predictors to predict well, 
so the error on the test set is too large.\\
In the second case there are too many predictors, and training error do 
not gives us any information, as happened in the previous example. 

\paragraph{Noisy labels}
In practice there is no $f^* : X \rightarrow Y$ such that $f^*(x) = y$, 
for all examples $(x,y)$. This means $y$ is noisy given $x$, for instance, 
the same data point may be observed with different labels.

This can happen in two scenarios:
\begin{enumerate}
    \item when there are \emph{humans in the loop}, as human decision 
    can be ambiguous
    \item lack of information, if we base our predictions on vectors and 
    they do not contain sufficient information, a prediction can't be made 
    precisely, as multiple labels could be linked to the same vector
\end{enumerate}

\section{NN classifiers}
Let's consider the case where data is made of coordinates and labels are integers:
$$x = (x_1, x_2) \in \mathbb{R},\;S = (x_1, y_1), \dots,(x_m, y_m),\;y_t \in \{-1, +1\}$$
A really simple approach to classification is to consider the \emph{nearest neighbor rule}.

\subsection{Nearest neighbor predictor}
A new data point is classified looking at the class of the nearest training point.
This approach induces a partition of the space in Voronoi cells. A distance 
function is needed, for instance the Euclidean distance.\\
If there's a tie we can specify a rule to break it.

The nearest neighbor rule generates a predictor with zero training error, 
on the other end, a predictor is made of the entire training set, as all the data points
are needed to compute a prediction.

\subsection{K-nearest neighbor}
A generalization of the nearest neighbor rule can be using the majority of the labels 
of the closest $K$ training points.
$K$ is odd to avoid ties.

Varying the $K$ parameter induces different classification boundaries, 
for instance, if $K$ equals to the number of training points, the prediction 
is always the major label. The number of \emph{switches} in the classification 
decreases by increasing $K$.

Usually, with a small parameter the predictor is overfitting the data, while 
with a large parameter underfitting occurs.

\paragraph{Extensions}
K-NN can be extended to multi-class classification and regression, 
in the second we can compute the average of the closest points.

\section{Tree predictors}
K-nn works only for numerical attributes, we want now to generalize
to heterogeneous data.
The main idea is to divide the points with orthogonal lines in the space, 
for instance, people that are younger than 30 and smokes, etc.

\subsection{Structure}
A tree predictor is a ordered rooted tree where each node has many children.
Each children represent a decision made considering the value
of on a certain categorical parameter or a function over a numerical value.

Each node has at least two children or is a leaf, i.e. a node where a prediction is 
made.

\paragraph{Split function}
Each internal node is associated with a test, so, given an attribute 
$i$ and a node $u$ with $k$ children, there is a function
$$f : X_i \rightarrow \{1, \dots, k\}$$
that partitions the values of the attribute among the children.
For instance:
\[ 
    f(x_1) = \begin{cases}
        1 \mathit{\;if\;} x_1 = c\\
        2 \mathit{\;if\;} x_1 = d\\
        3 \mathit{\;otherwise}
    \end{cases}\]

\begin{remark}
    The function typically considers only one attribute to avoid 
    comparing attributes of different domains.
\end{remark}

\paragraph{Leaves labels}
Leaves nodes are tagged by labels $y \in Y$, so when the visit reaches a leaf 
a prediction is made.

\subsection{Prediction}
We take a specific data point. This point is passed to the root, that will 
returns a specific child index, based on the split function evaluation 
performed on the data point.

This continue recursively, until a leaf node is reached, at this point 
a prediction in made, according to the label stored in the reached leaf 
node.

The prediction $h_T(x)$ is always a label stored in some leaf, in particular, the one 
reached by the path followed by the data point.

\subsection{Training}
Given a training set $S$, how can we build a tree classifier?

Let's simplify the task by considering binary classification, 
$Y = \{+1, -1\}$ 
and complete binary trees, so each node has either zero or 
two children.

The training set is of the form $S = (x_1,y1), \dots , (x_m, y_m)$, 
where each $x_i$ is made of multiple categorical and numerical attributes.
The loss taken into consideration is the zero-one loss.

\paragraph{Single starting node}
We start as a single node, the root, and the label associated with it is the 
majority of labels in $S$. We made a constant classifier.

\paragraph{Splitting the node}
We now consider a certain split function $f_i$, that split the dataset into 
two leaves, $l$ and $l^\prime$. We obtain:
\begin{enumerate}
    \item $S_l = \{(x_t, y_t), f_i(x_t) \mathit{\;routed\;to\;} l\}$
    \item $S_{l^\prime} = \{(x_t, y_t), f_i(x_t) \mathit{\;routed\;to\;} l^\prime\}$
\end{enumerate}
There's a need to decide which label to associate to the two leaves. We can 
pick the majority of labels contained in each one of them. 
this minimize the training error.

\paragraph{Training error}
Let $T$ be a certain tree classifier, $S_l$ is the training points routed to the leaf $l$,
$N_l = |S_l|$, $y_l$ the majority of labels in $S_l$.
$$S_l^+ = \{ (x_t, y_t) \in S_l, y_t = +1\},\;\;S_l^- = \{ (x_t, y_t) \in S_l, y_t = -1\}$$
\[
    y_l = \begin{cases}
        +1 \mathit{\;if\;} N_l^+ \geq N_l^-\\
        -1 \mathit{\;otherwise}
    \end{cases}\]
Let's compute the error, where $I$ is one if the condition is true
\begin{equation}
    \begin{aligned}
        \hat{l}_j(h_t) = \frac{1}{m}\sum_{t=1}^m I(h_t(x_t) \neq y_t)\\
        = \frac{1}{m}\min\{N_l^+, N_l^-\}
    \end{aligned}
\end{equation}
If we take the sum of the positive and negative sets over all leaves, we 
obtain the cardinality of $|S|$ 
$$\sum_l(N_l^+ + N_l^-) = m = |S|$$
We can keep on going with the previous equation:
\begin{equation}
    \begin{aligned}
        \hat{l}_j(h_t) = \frac{1}{m}\min\{N_l^+, N_l^-\}\\
        \hat{l}_j(h_t) = \frac{1}{m}\min\bigg\{\frac{N_l^+}{N_l}, \frac{N_l^-}{N_l}\bigg\}N_l\\
        \hat{l}_j(h_t) = \Psi\bigg(\frac{N_l^+}{N_l}\bigg)N_l && \text{Where\;} \Psi(a) = \min\{a, 1-a\}
    \end{aligned}
\end{equation}
Given a certain tree, 
we can consider the training error 
\begin{equation}
    \Psi\bigg(\frac{N_l^+}{N_l}\bigg)N_l = 
    \Psi\bigg(\frac{N_{l^\prime}^+}{N_{l^\prime}}
    \frac{N_{l^\prime}}{N_l}+\frac{N_{l^{\prime\prime}}^+}{N_{l^{\prime\prime}}}
    \frac{N_{l^{\prime\prime}}}{N_l}
    \bigg)N_l
\end{equation}

If we plot $\Psi$ we can see it is concave, so we can apply the \emph{Jenses inequiality}:
$$\forall a,b \in [0,1], \forall \alpha \in [0,1], 
\Psi(\alpha a + (1-\alpha)b) \geq \alpha \Psi(a) + (1-\alpha)\Psi(b)$$

So we keep going with the previous equation\footnote{Here we apply the jensen inequality
to the previous}
\begin{equation}
    \begin{aligned}
        \Psi\bigg(\frac{N_{l^\prime}^+}{N_{l^\prime}}
    \frac{N_{l^\prime}}{N_l}+\frac{N_{l^{\prime\prime}}^+}{N_{l^{\prime\prime}}}
    \frac{N_{l^{\prime\prime}}}{N_l}
    \bigg)N_l \geq 
    \bigg(\frac{N_{l^\prime}}{N_l}\Psi\bigg(\frac{N_{l^\prime}^+}{N_{l^\prime}}
    \bigg) + \frac{N_{l^{\prime\prime}}}{N_l}\Psi\bigg(\frac{N_{l^{\prime\prime}}^+}{N_{l^{\prime\prime}}}\bigg)\bigg)N_l\\
    = N_{l^\prime}\Psi\bigg(\frac{N_{l^\prime}^+}{N_{l^\prime}}
    \bigg) + N_{l^{\prime\prime}}\Psi\bigg(\frac{N_{l^{\prime\prime}}^+}{N_{l^{\prime\prime}}}\bigg)
    \end{aligned}
\end{equation}

So the error before splitting is bigger or equal 
to the error after splitting, so by splitting recursively we 
obtain a reduction of the training error.
$$\Psi\bigg(\frac{N_l^+}{N_l}\bigg)N_l \geq 
\Psi\bigg(\frac{N_{l^\prime}^+}{N_{l^\prime}}
    \bigg)N_{l^\prime} + \Psi\bigg(\frac{N_{l^{\prime\prime}}^+}{N_{l^{\prime\prime}}}\bigg)N_{l^{\prime\prime}}$$

This means replacing the leaf node $S_l$ obtained by the previous split 
with two new leaves $S_{l^\prime}$, $S_{l^{\prime\prime}}$.
If $\frac{N_l^+}{N_l} \approx \frac{1}{2}$, then the split is good whenever 
$\frac{N_{l^\prime}^+}{N_{l^\prime}}$ and 
$\frac{N_{l^{\prime\prime}}^+}{N_{l^{\prime\prime}}}$ are close to either 0 or 1.

\paragraph{Stopping criterion}
If the tree keeps splitting, the training error will go to 0, as 
all leaves will be pure, i.e. all labels are uniform inside a leaf.
This means overfitting.\footnote{Its the same principle of small K in K-NN}

So the objective is to grow the tree minimizing the training error, by 
using the minimum number of nodes. Every time we split we would like 
to fix as many mistakes as possible. For the sake of computation efficiency, 
we perform greedy cuts.

\paragraph{Other error (split) functions}
In practice we do not use $\Psi(a) = \min(a, 1-a)$, but some other ones:
\begin{itemize}
    \item \emph{Gini function}: $\Psi_2(p) = 2p(1-p)$
    \item \emph{Scaled entropy}: $\Psi_3(p) = -\frac{p}{2}\log_2 p - \frac{1-p}{2}\log_2(1-p)$
\end{itemize}

Those are upper-bounds of the training error, this means considering 
splits that would be excluded by the original $\Psi$ function.
This surrogate functions are better because they can move things around and 
create possible new splits, they help to not get stuck in local minima where 
growing two nodes seems to not help the situation, thus they help 
grow the tree more efficiently.

\paragraph{Usage}
Tree classifiers can also be extended to multi-class classification and regression.
In the first case, the major class is chosen, while in the second we take the mean of the value.
