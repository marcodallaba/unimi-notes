\section{Topic modeling}

\paragraph{Vector space models problems}
The approaches seen so far did not take into 
consideration semantics of words. 
We understood that the vector space models suffer 
from high dimensionality, the terms also could be synonyms, 
leading to ambiguity, in fact two words that means 
the same thing are two different dimensions in the model.

\subsection{Latent Semantic Indexing}
The goal is to discover topics that motivate data
by using matrix factorization techniques, while 
taking in consideration the possibility of expressing
the same topic with different words.


\subsection{Latent Dirichlet Allocation}
