\section{Sincronizzazione}

\paragraph{Clock interno}
Ogni nodo in un sistema distribuito ha un clock interno. 
Esistono alcuni problemi, ad esempio, considerando due eventi 
consecutivi su due macchine differenti, il secondo 
evento potrebbe avere tempo inferiore al primo, 
se il clock del nodo che l'ha eseguito è leggermente minore dell'altro nodo.

Questo tipo di problemi porta inevitabilmente a comportamenti 
inaspettati, è necessaria una sincronizzazione.
 
\paragraph{È possibile una sincronizzazione perfetta?}
Sostanzialmente no, non è possibile pensare di avere una 
sincronizzazione perfetta in un sistema distribuito, 
si punta ad una certa precisione.

\subsection{Orologi fisici}

Nel contesto degli orologi fisici, si fa riferimento al 
tempo UTC. Esso è calcolato osservando fenomeni naturali ed
astronomici.
 
In particolare il tempo UTC fa riferimento al 
TAI, il tempo internazionale atomico, regolato 
aggiungendo \emph{leap seconds} per allinearlo al tempo 
solare.

\paragraph{Clock lento e veloce}
Facendo riferimento all'UTC, si parla di clock perfetto 
se il rapporto tra clock e UTC equivale ad uno.
Il clock invece è veloce se il rapporto è maggiore 
di uno e lento altrimenti.

Se il clock dei nodi di un sistema distribuito non è perfetto, 
saranno necessarie operazioni di sincronizzazione di tanto 
in tanto.

\subsubsection{Metodi di sincronizzazione}

\paragraph{Sincronizzazione tramite GNSS}
Per gli orologi fisici è possibile utilizzare 
il GNSS per capire la posizione attuale. 
Il tempo ottenuto tramite questo metodo, 
che sfrutta più satelliti, 
è preciso ai micro o anche ai nano secondi. 

I satelliti hanno a bordo un orologio atomico.
Il ricevitore GNSS manda un messaggio ai satelliti e, 
osservando il tempo di risposta e interpolando 
i segnali ricevuti, determina la posizione attuale e 
la deviazione dal tempo UTC. Ovviamente la 
posizione è approssimata come il tempo che si calcola.

\paragraph{Algoritmo di Cristian e NTP}
L'idea è quella di chiedere il tempo preciso ad un server,
tenendo in considerazione la latenza della richiesta.

Quindi, il client manda la richiesta al server NTP, 
esso manda la risposta, ma ovviamente esistono ritardi.
I messaggi contengono perciò timestamp, sia lato client che 
lato server, si stimano i ritardi di comunicazione e si calcola
il tempo attuale di conseguenza. Il procedimento 
viene ripetuto più volte per stimare bene la latenza e il 
risultato è preciso ai millisecondi.

\paragraph{Algortimo di Berkeley}
Non sempre è necessario sincronizzare gli orologi 
di un sistema distribuito con il tempo esterno. 

Esiste quindi un server che fa da \emph{time deamon}, 
esso manda il suo orario a tutti i nodi 
del sistema, essi rispondono con la differenza 
del loro tempo rispetto a quella del time deamon. 
Il nodo deamon calcola la media degli orari del sistema 
e manda il risultato a tutti. 

La latenza del procedimento è ignorata, si assume che 
esistano comunicazioni pressoché istantanee.

Inoltre, il tempo di un nodo non si riporta mai indietro, 
visti i possibili problemi di inconsistenza che il procedimento 
creerebbe. Si rallenta semplicemente il tempo fino a quando 
non si allinea con quello del nodo deamon.

\subsection{Orologi logici}

In molti casi non è necessario che i nodi siano sincronizzati 
rispetto ai loro clock fisici, potrebbe essere abbastanza 
conoscere un'ordine parziale di eventi sul sistema distribuito.

\paragraph{Idea}
Quello che serve è un modo per far concordare i nodi sulla
sequenza di certi eventi, dove un evento 
è interno o l'invio o ricezione di un messaggio. 

Si mantiene un contatore e ogni volta che accade un evento 
esso viene aumentato. Si nota che i contatori 
dei nodi potrebbero avere valori differenti.

\subsubsection{Algoritmo di Lamport}

L'idea dell'algoritmo è che, dati due eventi 
$A, B$ l'espressione $A \rightarrow B$ indica la relazione 
che $A$ è accaduto prima di $B$, ed essa è transitiva.

Dato $C(a)$ il valore del clock logico assegnato 
al momento in cui $a$ è accaduto, l'obiettivo dell'algoritmo 
è far valere la seguente espressione
$$A \rightarrow B \implies C(a) < C(b)$$

\paragraph{Logica}
L'aggiornamento del counter $C_i$ per il 
processo $P_i$ avviene come segue: 
\begin{enumerate}
    \item Prima di eseguire un evento, il processo $P_i$ 
    esegue $C_i \gets C_i + 1$;
    \item Se il processo $P_i$ manda un messaggio $m$ a $P_j$, 
    setta il timestamp di $m$ con il valore del counter attuale, 
    $ts(m) \gets C_i$;
    \item $P_j$ quando riceve il messaggio aggiorna il suo 
    contatore secondo la logica $C_j \gets \max(C_j, ts(m)) + 1$.
\end{enumerate}
Si nota che non è detto che si riesca a dare un ordine per ogni 
coppia di eventi, ma solo tra quelli collegati da un messaggio.

\paragraph{Implementazione}
All'interno del sistema si può pensare all'Implementazione
dell'algoritmo come middleware.

\paragraph{Problematiche}
L'algoritmo può essere modificato aggiungendo un contatore, 
ovvero, il processo $P_i$ assegna all'evento 
$e$, $C_i(e).i$ dove $i$ è il suo indice.

Se due eventi nel sistema hanno lo stesso $C$, si riesce 
a disambiguare scegliendo in ordine l'evento con indice 
del processo minore.

\paragraph{Applicazioni}
Una possibile applicazione dell'algoritmo è quella 
della replica di database.

\paragraph{Totally ordered multicast}
Un'applicazione dell'algoritmo di Lamport è l'ordinare comunicazioni multicast.
Si assume che l'ordine di invio e di consegna sia rispettato, e che i messaggi 
siano consegnati.

Un utente manda un messaggio e lo mette in una coda locale, ogni 
processo che riceve mette in coda, ordinando per timestamp e manda un ack a tutti. 

L'operazione viene eseguita quando un messaggio è in testa alla coda 
e tutti gli ack per quel messaggio sono stati ricevuti. Per l'assunzione fatta inizialmente 
i messaggi arrivano in ordine quindi non ci sono problemi di ordine.

\section{Esclusione ed elezione}
\subsection{Algoritmi di mutua esclusione}
\label{mutua}
È necessaria mutua esclusione quando esistono risorse 
comuni a cui non possono accedere più nodi in contemporanea.

\paragraph{Soluzione centralizzata}
Una soluzione semplice consiste nell'usare un nodo 
coordinatore che regola l'accesso alla risorsa 
condivisa. Si può utilizzare una coda gestita dal coordinatore.

\paragraph{Soluzione distribuita}
L'idea è che se un processo P deve utilizzare una risorsa
R, costruisce un messaggio contenente il suo id, il nome 
della risorsa e un timestamp. Manda poi il messaggio a tutti, 
incluso se stesso.

Si assume che esista ordine totale degli eventi, tramite 
ack.

Si pensi ora a due processi 0 e 2 che vogliono accedere 
alla risorsa $R$ e il processo 3 che non fa nulla.\\
P0 manda un messaggio con timestamp 8, P2 uno con timestamp 12.
P3 risponde OK ad entrambi, mentre, P2 risponde OK a P0, 
non il viceversa, visto che il timestamp di P0 è minore di P2.

A questo punto P0 aggiunge nella sua coda P2 e ottiene la 
risorsa. Al termine manda il messaggio di OK a P2, che è l'unico 
processo nella sua coda che sta aspettando il messaggio 
per accedere alla risorsa condivisa.

\paragraph{Problematiche distribuite}
Una mancanza di risposta potrebbe essere un crash, 
inoltre il richiedere l'intervento di tutti 
i nodi ogni volta che si vuole accedere ad una risorsa non è
desiderabile.

\paragraph{Algoritmo ad anello}
Si crea una struttura logica sopra la rete distribuita ad anello.
Si considera un token, che viene scambiato tra i nodi della rete.

Esso viene inviato dal processo $i$ al processo $(i+1)\mathit{mod\;}n$.
Se un processo è interessato ad usare una risorsa, può farlo 
quando riceve il token, quando ha finito, o se non interessato, 
manda il messaggio al processo successivo.

Esistono problemi, ad esempio il blocco di un nodo 
rompe la circolazione del token, ma può essere risolto avendo più 
successori a cui mandare il token in caso di errore. Esiste però 
anche la possibilità di perdere il token se il nodo che lo ha crasha.

\paragraph{Confronto tra gli algoritmi}
Nell'algoritmo centralizzato servono meno messaggi, visto che ne bastano 
3 per ottenere la risorsa, in quello distribuito si parla 
dell'ordine di $n$ messaggi dove $n$ è il numero di nodi, 
mentre in quello ad anello si può osservare anche un numero 
infinito di messaggi, nel caso in cui nessuno voglia utilizzare 
la risorsa condivisa.

\subsection{Algoritmi di elezione}
Questi algoritmi hanno come obiettivo eleggere un coordinatore 
tra i nodi. 
Potrebbe essere utile ad esempio per ottenere il coordinatore dell'algoritmo 
centralizzato di mutua esclusione introdotto in sezione \vref{mutua}.
L'obiettivo è quello di eleggere il processo con identifier più alto.

\subsubsection{Algoritmo del bullo}
Un processo, quando si accorge che il coordinatore 
è fallito, manda un messaggio di elezione 
al precedente coordinatore e ai processi con identifier più alto.

\paragraph{Esecuzione}
L'esecuzione procede come segue 
\begin{itemize}
    \item Per esempio, dati 7 processi, il 4, accortosi che il coordinatore 
    è crashato, manderà un messaggio a 5, 6 e 7, dove l'ultimo è il coordinatore;
    \item I processi 5 e 6 si prendono in carico l'elezione, 
    mandando un messaggio di ok, 5 e 6 ripetono il procedimento 
    di 4;
    \item A questo punto 6 risponde ok a 5.
    6 prova ad eseguire il procedimento di 4, 7 non risponde più
    e quindi capisce che è il nuovo coordinatore;
    \item 6 manda in broadcast che è il nuovo coordinatore.
\end{itemize}

\paragraph{Problematiche}
Una domanda che ci si può fare, cosa succede se due processi 
iniziano un processo di elezione contemporaneamente?
Potrebbe non essere un problema, se il sistema non è estremamente 
dinamico. I processi di elezione portano allo stesso coordinatore.

Se si parte da un nodo con id molto basso, nella rete circolano 
molti messaggi.

Se un coordinatore vecchio si risveglia bisogna gestirlo. Potrebbe ad 
esempio mandare un nuovo messaggio di elezione.

\subsubsection{Elezione ad anello}

Si continua con l'idea dell'anello della sezione precedente.
Si crea quindi la struttura logica, ogni nodo ha un id e i messaggi 
circolano in senso orario, dove il successore è calcolato in modulo 
$n$.

\paragraph{Esecuzione}
L'esecuzione dell'algoritmo procede come segue, si assume che 
tutti i processi inizialmente sono \emph{non partecipanti}:
\begin{itemize}
    \item Un processo $P_k$ che si accorge che il coordinatore è fallito, 
    si setta \emph{partecipante} e invia al successore un messaggio;
    del tipo $[\mathit{Election}, \mathit{ID}(P_k)]$
    \item Un processo $P_m$ che riceve $[\mathit{Election}, \mathit{ID}(P_k)]$:
    \begin{itemize}
        \item Se $\mathit{ID}(P_k) > \mathit{ID}(P_m)$ manda il messaggio 
        marcandosi come \emph{partecipante};
        \item Se $\mathit{ID}(P_k) < \mathit{ID}(P_m)$ se il processo 
        non è partecipante si setta e manda $[\mathit{Election}, \mathit{ID}(P_m)]$
        al successore;
        \item Se $k = m$ il processo è diventato coordinatore, si setta 
        come non partecipante e manda al successore $[\mathit{Elected}, \mathit{ID}(P_m)]$.
    \end{itemize}
\end{itemize}

\paragraph{Caso pessimo}
Se il processo con ID più alto è il vicino in senso antiorario 
di chi inizia l'elezione, sono necessari $n-1$ messaggi per arrivare ad esso, 
poi altri $n$ messaggi per diffondere il nuovo ID massimale, 
e infine altri $n$ messaggi \emph{Elected}, quindi $3n-1$.

Si fa notare infine che elezioni multiple non sono un problema, infatti 
il flag \emph{partecipante}, \emph{non partecipante} permette di evitare la propagazione 
di un'elezione concorrente.